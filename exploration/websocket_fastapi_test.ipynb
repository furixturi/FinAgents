{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Websocket streaming test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://microsoft.github.io/autogen/docs/notebooks/agentchat_websockets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load env and set up configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use these in AutoGen's `llm_config = { \"config_list\": [...]}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "config_gpt_4o = {\n",
    "    \"model\": os.environ.get(\"GPT_4O_MODEL\"),\n",
    "    \"api_type\": \"azure\",\n",
    "    \"api_key\": os.environ.get(\"GPT_4O_API_KEY\"),\n",
    "    \"base_url\": os.environ.get(\"GPT_4O_AZURE_ENDPOINT\"),\n",
    "    \"api_version\": os.environ.get(\"GPT_4O_API_VERSION\"),\n",
    "}\n",
    "\n",
    "\n",
    "config_gpt_4_turbo = {\n",
    "    \"model\": os.environ.get(\"GPT_4_TURBO_MODEL\"),\n",
    "    \"api_type\": \"azure\",\n",
    "    \"api_key\": os.environ.get(\"GPT_4_TURBO_API_KEY\"),\n",
    "    \"base_url\": os.environ.get(\"GPT_4_TURBO_AZURE_ENDPOINT\"),\n",
    "    \"api_version\": os.environ.get(\"GPT_4_TURBO_API_VERSION\"),\n",
    "}\n",
    "\n",
    "\n",
    "config_gpt_35_turbo = {\n",
    "    \"model\": os.environ.get(\"GPT_35_TURBO_MODEL\"),\n",
    "    \"api_type\": \"azure\",\n",
    "    \"api_key\": os.environ.get(\"GPT_35_TURBO_API_KEY\"),\n",
    "    \"base_url\": os.environ.get(\"GPT_35_TURBO_AZURE_ENDPOINT\"),\n",
    "    \"api_version\": os.environ.get(\"GPT_35_TURBO_API_VERSION\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with a Websocket Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Connection Handler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each new client connection utilizing websockets, the websocket server automatically initiates a new instance of `IOWebsockets` class for managing client-server data flow. It will be passed to the handler as the `iostream` parameter.\n",
    "\n",
    "Utilize this to initialize everything to manage the interactive session with AutoGen:\n",
    "- get initial input message\n",
    "- instantiate the `UserProxyAgent` and other agents, also register functions the agents need to use\n",
    "- initiate chat with the `UserProxyAgent`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dependenies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from datetime import datetime\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "from websockets.sync.client import connect as ws_connect\n",
    "\n",
    "import autogen\n",
    "from autogen.io.websockets import IOWebsockets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define handler function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_connect(iostream: IOWebsockets) -> None:\n",
    "    print(\n",
    "        f\" - on_connect(): Connected to client using IOWebsockets {iostream}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    print(\" - on_connect(): Receiving a message to the client\", flush=True)\n",
    "\n",
    "    # Get the initial message from the client\n",
    "    initial_msg = iostream.input()\n",
    "\n",
    "    # Define a chatbot ConversableAgent that can use weather_forcast function\n",
    "    agent = autogen.ConversableAgent(\n",
    "        name=\"chatbot\",\n",
    "        system_message=\"Complete a task given to you and reply TERMINATE when the task is done. If asked about the weather, use tool 'weather_forecast(city)' to get the weather forecast for a city.\",\n",
    "        # system_message=\"Complete a tasks given to you. If asked about the weather, use tool 'weather_forecast(city)' to get the weather forecast for a city.\",\n",
    "        llm_config={\n",
    "            \"config_list\": [config_gpt_4o, config_gpt_4_turbo, config_gpt_35_turbo],\n",
    "            \"stream\": True,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Define code executor using UserProxyAgent\n",
    "    user_proxy = autogen.UserProxyAgent(\n",
    "        name=\"user_proxy\",\n",
    "        system_message=\"A proxy for the user\",\n",
    "        # is_termination_msg=False,\n",
    "        is_termination_msg=lambda x: x.get(\"content\", \"\") and x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "        human_input_mode=\"ALWAYS\",\n",
    "        max_consecutive_auto_reply=10,\n",
    "        code_execution_config=False,\n",
    "    )\n",
    "\n",
    "    # Functions that agent can use\n",
    "    def weather_forecast(city: str) -> str:\n",
    "        return f\"The weather forcast for {city} at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} is 25°C and sunny.\"\n",
    "\n",
    "    autogen.register_function(\n",
    "        weather_forecast,\n",
    "        caller=agent,\n",
    "        executor=user_proxy,\n",
    "        description=\"Weather forecast for a city\",\n",
    "    )\n",
    "\n",
    "    # Initiate conversation\n",
    "    print(\n",
    "        f\" - on_connect(): Initiating chat with agent {agent} using message {initial_msg}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    user_proxy.initiate_chat(agent, message=initial_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test websocket server with a Python client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - test_setup() with websocket server running on ws://127.0.0.1:8765\n",
      " - on_connect(): Connected to client using IOWebsockets <autogen.io.websockets.IOWebsockets object at 0x7f0d99959760>\n",
      " - on_connect(): Receiving a message to the client\n",
      " - Connected to server on ws://127.0.0.1:8765\n",
      " - Sending message to server\n",
      " - on_connect(): Initiating chat with agent <autogen.agentchat.conversable_agent.ConversableAgent object at 0x7f0de40b29c0> using message Check current weather in Tokyo and write a Haiku about it.\n",
      "\u001b[33muser_proxy\u001b[0m (to chatbot):\n",
      "\n",
      "Check current weather in Tokyo and write a Haiku about it.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mchatbot\u001b[0m (to user_proxy):\n",
      "\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_ba3qVvqFWRT4Ox5pjAF2VObk): weather_forecast *****\u001b[0m\n",
      "Arguments: \n",
      "{\"city\": \"Tokyo\"}\n",
      "\u001b[32m*********************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION weather_forecast...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to chatbot):\n",
      "\n",
      "\u001b[33muser_proxy\u001b[0m (to chatbot):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_ba3qVvqFWRT4Ox5pjAF2VObk) *****\u001b[0m\n",
      "The weather forcast for Tokyo at 2024-06-09 13:18:34 is 25°C and sunny.\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[32mIn Tokyo's bright sun,\n",
      "Golden rays dance, warm embrace—\n",
      "Summer whispers, \"Shine.\"\n",
      "\n",
      "TERMINATE\u001b[0m\n",
      "\n",
      "\u001b[33mchatbot\u001b[0m (to user_proxy):\n",
      "\n",
      "In Tokyo's bright sun,\n",
      "Golden rays dance, warm embrace—\n",
      "Summer whispers, \"Shine.\"\n",
      "\n",
      "TERMINATE\n",
      "\n",
      " - Received TERMINATE message. Exiting...\n"
     ]
    }
   ],
   "source": [
    "with IOWebsockets.run_server_in_thread(on_connect=on_connect, port=8765) as uri:\n",
    "    print(f\" - test_setup() with websocket server running on {uri}\", flush=True)\n",
    "    \n",
    "    with ws_connect(uri) as websocket:\n",
    "        print(f\" - Connected to server on {uri}\", flush=True)\n",
    "        print(f\" - Sending message to server\", flush=True)\n",
    "        websocket.send(\"Check current weather in Tokyo and write a Haiku about it.\")\n",
    "        \n",
    "        while True:\n",
    "            message = websocket.recv()\n",
    "            message = message.decode(\"utf-8\") if isinstance(message, bytes) else message\n",
    "            \n",
    "            print(message, end=\"\", flush=True)\n",
    "            \n",
    "            if \"TERMINATE\" in message:\n",
    "                print()\n",
    "                print(\" - Received TERMINATE message. Exiting...\", flush=True)\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test websocket server with a frontend and app server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HTML Template - frontend UI for user interaction\n",
    "- FastAPI application - app server to serve HTML frontend\n",
    "- Websocket server - stream interaction with AutoGen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import asynccontextmanager\n",
    "from pathlib import Path\n",
    "from fastapi import FastAPI\n",
    "from fastapi.responses import HTMLResponse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frontend HTML and JS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "    <head>\n",
    "        <title>Autogen websocket test</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>WebSocket Chat</h1>\n",
    "        <form action=\"\" onsubmit=\"sendMessage(event)\">\n",
    "            <input type=\"text\" id=\"messageText\" autocomplete=\"off\"/>\n",
    "            <button>Send</button>\n",
    "        </form>\n",
    "        <ul id='messages'>\n",
    "        </ul>\n",
    "        <script>\n",
    "            var ws = new WebSocket(\"ws://localhost:8080/ws\");\n",
    "            ws.onmessage = function(event) {\n",
    "                var messages = document.getElementById('messages')\n",
    "                var message = document.createElement('li')\n",
    "                var content = document.createTextNode(event.data)\n",
    "                message.appendChild(content)\n",
    "                messages.appendChild(message)\n",
    "            };\n",
    "            function sendMessage(event) {\n",
    "                event.preventDefault()\n",
    "                var input = document.getElementById(\"messageText\")\n",
    "                console.log(\"Will send: \", input.value)\n",
    "                ws.send(input.value)\n",
    "                input.value = ''\n",
    "            }\n",
    "        </script>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FastAPI App "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "@asynccontextmanager\n",
    "async def run_websocket_server(app):\n",
    "    with IOWebsockets.run_server_in_thread(on_connect=on_connect, port=8080) as uri:\n",
    "        print(f\"Websocket server started at {uri}.\", flush=True)\n",
    "        yield\n",
    "\n",
    "app = FastAPI(lifespan=run_websocket_server)\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def get():\n",
    "    return HTMLResponse(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use `uvicorn` to run the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [324416]\n",
      "INFO:     Waiting for application startup.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Websocket server started at ws://127.0.0.1:8080.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:36142 - \"GET / HTTP/1.1\" 200 OK\n",
      " - on_connect(): Connected to client using IOWebsockets <autogen.io.websockets.IOWebsockets object at 0x7f0d959b2210>\n",
      " - on_connect(): Receiving a message to the client\n",
      " - on_connect(): Initiating chat with agent <autogen.agentchat.conversable_agent.ConversableAgent object at 0x7f0d9610ed80> using message Hello, how are you?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [324416]\n"
     ]
    }
   ],
   "source": [
    "import uvicorn\n",
    "\n",
    "config = uvicorn.Config(app)\n",
    "server = uvicorn.Server(config)\n",
    "await server.serve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
